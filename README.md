# Machine Learning Backend - An√°lise de Sobreviv√™ncia Haberman

[![MIT License](https://img.shields.io/badge/License-MIT-blue.svg)](https://opensource.org/licenses/MIT)
[![Python 3.x](https://img.shields.io/badge/python-3.x-brightgreen.svg)](https://www.python.org/)
[![scikit-learn](https://img.shields.io/badge/scikit--learn-1.3-orange.svg)](https://scikit-learn.org/)
[![CI Pipeline](https://github.com/Gilmarregis/Projeto-Machine-Learning/workflows/CI%20Pipeline/badge.svg)](https://github.com/Gilmarregis/Projeto-Machine-Learning/actions)
[![Docker](https://img.shields.io/badge/docker-ready-blue.svg)](https://www.docker.com/)
[![MLflow](https://img.shields.io/badge/mlflow-tracking-orange.svg)](https://mlflow.org/)
[![Prometheus](https://img.shields.io/badge/monitoring-prometheus-red.svg)](https://prometheus.io/)
[![Code Coverage](https://codecov.io/gh/Gilmarregis/Projeto-Machine-Learning/branch/main/graph/badge.svg)](https://codecov.io/gh/Gilmarregis/Projeto-Machine-Learning)

Um projeto **profissional** de Machine Learning para an√°lise de sobreviv√™ncia de pacientes com c√¢ncer de mama usando o dataset Haberman, implementado com **pipeline ETL completo**, **CI/CD automatizado**, **containeriza√ß√£o Docker**, **monitoramento Prometheus**, **MLOps** e **arquitetura modular**.

## üìã Descri√ß√£o

Este projeto implementa uma **solu√ß√£o completa de Machine Learning em n√≠vel empresarial** usando o famoso **Dataset Haberman** para prever a sobreviv√™ncia de pacientes que passaram por cirurgia de c√¢ncer de mama. O sistema utiliza **arquitetura modular**, **pipeline ETL profissional**, **m√∫ltiplos algoritmos** com **valida√ß√£o cruzada**, **sele√ß√£o autom√°tica do melhor modelo** e **infraestrutura DevOps completa**.

## üèóÔ∏è Arquitetura do Sistema

### Pipeline ETL Profissional
```mermaid
graph TD
    A[Raw Data Sources] --> B[Extract Module]
    B --> C[Transform Module]
    C --> D[Load Module]
    D --> E[Model Training]
    E --> F[Model Evaluation]
    F --> G[MLflow Registry]
    G --> H[API Deployment]
    H --> I[Prometheus Monitoring]
    I --> J[Alerting]
```

### Arquitetura de Microservi√ßos
```mermaid
graph TB
    subgraph "Data Layer"
        CSV[CSV Files]
        DB[Database]
        API_EXT[External APIs]
    end
    
    subgraph "ETL Pipeline"
        EXT[Extract Service]
        TRANS[Transform Service]
        LOAD[Load Service]
    end
    
    subgraph "ML Layer"
        TRAIN[Training Service]
        PRED[Prediction API]
        MON[Monitoring]
    end
    
    subgraph "Infrastructure"
        DOCKER[Docker Containers]
        CI[CI/CD Pipeline]
        PROM[Prometheus]
    end
    
    CSV --> EXT
    DB --> EXT
    API_EXT --> EXT
    EXT --> TRANS
    TRANS --> LOAD
    LOAD --> TRAIN
    TRAIN --> PRED
    PRED --> MON
    MON --> PROM
```

## üìä Sobre o Dataset Haberman

O **Haberman's Survival Dataset** √© um conjunto de dados cl√°ssico em Machine Learning, coletado no Hospital Billings de Chicago entre 1958 e 1970. Cont√©m informa√ß√µes sobre pacientes que passaram por cirurgia de c√¢ncer de mama.

### Caracter√≠sticas do Dataset:
- **306 inst√¢ncias** de pacientes
- **4 atributos** (3 features + 1 target)
- **Sem valores faltantes**
- **Balanceamento**: ~75% sobreviveram (classe 1), ~25% n√£o sobreviveram (classe 2)

### Atributos:
| Atributo | Tipo | Descri√ß√£o | Faixa |
|----------|------|-----------|-------|
| `age` | int | Idade do paciente no momento da opera√ß√£o | 30-83 anos |
| `year` | int | Ano da opera√ß√£o | 1958-1969 |
| `nodes` | int | N√∫mero de n√≥dulos linf√°ticos axilares positivos detectados | 0-52 |
| `survival_status` | int | **Target**: Status de sobreviv√™ncia (1=sobreviveu ‚â•5 anos, 2=morreu <5 anos) | 1 ou 2 |

### Import√¢ncia Cl√≠nica:
- **N√≥dulos linf√°ticos** s√£o o fator mais importante para progn√≥stico
- **Idade** pode influenciar na capacidade de recupera√ß√£o
- **Ano da opera√ß√£o** reflete avan√ßos m√©dicos ao longo do tempo

## üöÄ Funcionalidades Principais

### üîÑ Pipeline ETL Modular
- **Extract**: Extra√ß√£o de dados de m√∫ltiplas fontes (CSV, Database, APIs)
- **Transform**: Limpeza, engenharia de features e tratamento de outliers
- **Load**: Persist√™ncia de dados processados e modelos com metadata

### ü§ñ Machine Learning Avan√ßado
- **8 Algoritmos**: Compara√ß√£o autom√°tica com valida√ß√£o cruzada
- **MLflow Tracking**: Rastreamento de experimentos e modelos
- **Sele√ß√£o Autom√°tica**: Escolha do melhor modelo baseado em m√©tricas
- **Valida√ß√£o Robusta**: Cross-validation 5-fold para avalia√ß√£o confi√°vel

### üìä Monitoramento e Observabilidade
- **Prometheus Metrics**: M√©tricas de performance em tempo real
- **Structured Logging**: Logs estruturados para debugging
- **Health Checks**: Verifica√ß√£o de sa√∫de dos servi√ßos
- **Alerting**: Alertas autom√°ticos para anomalias

### üê≥ DevOps e Infraestrutura
- **Docker**: Containeriza√ß√£o completa da aplica√ß√£o
- **CI/CD**: Pipeline automatizado com GitHub Actions
- **Testing**: Testes unit√°rios e de integra√ß√£o
- **Security**: Verifica√ß√µes de seguran√ßa automatizadas

## ü§ñ Algoritmos Implementados

O sistema compara os seguintes algoritmos com otimiza√ß√£o de hiperpar√¢metros:

1. **Logistic Regression** - Classifica√ß√£o linear probabil√≠stica
2. **Random Forest** - Ensemble de √°rvores com bagging
3. **Support Vector Machine (SVM)** - Classifica√ß√£o com margens m√°ximas
4. **K-Nearest Neighbors (KNN)** - Classifica√ß√£o baseada em proximidade
5. **Decision Tree** - √Årvore de decis√£o interpret√°vel
6. **Naive Bayes** - Classifica√ß√£o probabil√≠stica bayesiana
7. **Gradient Boosting** - Ensemble com boosting sequencial
8. **Neural Network (MLP)** - Rede neural multicamadas

## üõ†Ô∏è Tecnologias e Stack

### Core ML Stack
- **Python 3.9+**: Linguagem principal
- **scikit-learn 1.3+**: Algoritmos de Machine Learning
- **pandas 2.0+**: Manipula√ß√£o de dados
- **numpy**: Computa√ß√£o num√©rica
- **matplotlib/seaborn**: Visualiza√ß√µes

### MLOps Stack
- **MLflow**: Tracking de experimentos e registry de modelos
- **Prometheus**: M√©tricas e monitoramento
- **Docker**: Containeriza√ß√£o
- **Flask**: API REST

### DevOps Stack
- **GitHub Actions**: CI/CD
- **pytest**: Framework de testes
- **flake8**: Linting de c√≥digo
- **mypy**: Type checking
- **codecov**: Cobertura de c√≥digo

### Infrastructure
- **Docker Compose**: Orquestra√ß√£o local
- **Makefile**: Automa√ß√£o de comandos
- **Requirements**: Gest√£o de depend√™ncias

## üì¶ Instala√ß√£o e Setup

### Pr√©-requisitos
- Python 3.9+
- Docker (opcional)
- Make (opcional)

### Instala√ß√£o Local

```bash
# Clone o reposit√≥rio
git clone https://github.com/Gilmarregis/Projeto-Machine-Learning.git
cd Projeto-Machine-Learning

# Instalar depend√™ncias
pip install -r requirements.txt

# Instalar depend√™ncias de desenvolvimento (opcional)
pip install -r requirements-dev.txt
```

### Instala√ß√£o com Docker

```bash
# Build da imagem
docker build -f docker/Dockerfile -t ml-haberman .

# Executar container
docker run -p 5000:5000 ml-haberman

# Ou usar docker-compose
docker-compose -f docker/docker-compose.yml up
```

### Usando Makefile

```bash
# Ver todos os comandos dispon√≠veis
make help

# Setup completo do ambiente
make setup

# Executar testes
make test

# Executar linting
make lint

# Treinar modelo
make train

# Executar API
make run-api

# Build Docker
make docker-build
```

## üîß Como Usar

### 1. Treinamento do Modelo

```bash
# Executar treinamento completo
python ML_model.py

# Ou usando make
make train
```

**O que acontece:**
1. **Extra√ß√£o**: Carrega dataset Haberman (306 amostras)
2. **Transforma√ß√£o**: An√°lise explorat√≥ria e prepara√ß√£o dos dados
3. **Compara√ß√£o**: Testa 8 algoritmos com valida√ß√£o cruzada 5-fold
4. **Sele√ß√£o**: Escolhe automaticamente o melhor modelo
5. **Treinamento**: Treina modelo final nos dados completos
6. **Valida√ß√£o**: M√©tricas detalhadas de performance
7. **Persist√™ncia**: Salva modelo como `best_model_nn.pkl`
8. **Logging**: Registra experimento no MLflow

### 2. Executar Pipeline ETL

```bash
# Executar pipeline completo
python -m src.data.extract
python -m src.data.transform
python -m src.data.load
```

### 3. API de Predi√ß√£o

```bash
# Iniciar API
python api_ML.py

# Ou usando make
make run-api
```

**Endpoint**: `POST http://localhost:5000/predict`

**Exemplo de requisi√ß√£o:**
```json
{
    "age": 45,
    "year": 1965,
    "nodes": 3
}
```

**Exemplo de resposta:**
```json
{
    "survival_status": 1,
    "probabilidade_sobrevivencia": 0.78,
    "probabilidade_obito": 0.22,
    "algoritmo_usado": "Neural Network",
    "confianca": "Alta",
    "timestamp": "2024-01-15T10:30:00Z"
}
```

### 4. Monitoramento

```bash
# Ver m√©tricas Prometheus
curl http://localhost:5000/metrics

# Health check
curl http://localhost:5000/health
```

## üìÅ Estrutura do Projeto

```
Machine Learning/
‚îú‚îÄ‚îÄ Machine Learning Backend.py    # C√≥digo principal
‚îú‚îÄ‚îÄ README.md                     # Este arquivo
‚îî‚îÄ‚îÄ logistic_regression_model.pkl # Modelo treinado (gerado ap√≥s execu√ß√£o)
```

## ü§ù Contribui√ß√£o

1. Fork o projeto
2. Crie uma branch para sua feature (`git checkout -b feature/AmazingFeature`)
3. Commit suas mudan√ßas (`git commit -m 'Add some AmazingFeature'`)
4. Push para a branch (`git push origin feature/AmazingFeature`)
5. Abra um Pull Request

## üìù Licen√ßa

Este projeto est√° sob a licen√ßa MIT. Veja o arquivo `LICENSE` para mais detalhes.

## üìû Contato

Para d√∫vidas ou sugest√µes, entre em contato atrav√©s dos issues do GitHub.

---

‚≠ê Se este projeto foi √∫til para voc√™, considere dar uma estrela!
