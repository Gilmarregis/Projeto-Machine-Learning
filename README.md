# Machine Learning Backend - AnÃ¡lise de SobrevivÃªncia Haberman

[![MIT License](https://img.shields.io/badge/License-MIT-blue.svg)](https://opensource.org/licenses/MIT)
[![Python 3.x](https://img.shields.io/badge/python-3.x-brightgreen.svg)](https://www.python.org/)
[![scikit-learn](https://img.shields.io/badge/scikit--learn-1.3-orange.svg)](https://scikit-learn.org/)

Um projeto de Machine Learning para anÃ¡lise de sobrevivÃªncia de pacientes com cÃ¢ncer de mama usando o dataset Haberman, implementado com mÃºltiplos algoritmos e validaÃ§Ã£o cruzada.

## ğŸ“‹ DescriÃ§Ã£o

Este projeto implementa uma anÃ¡lise completa de Machine Learning usando o famoso **Dataset Haberman** para prever a sobrevivÃªncia de pacientes que passaram por cirurgia de cÃ¢ncer de mama. O sistema compara 8 algoritmos diferentes e seleciona automaticamente o melhor modelo baseado em validaÃ§Ã£o cruzada.

## ğŸ“Š Sobre o Dataset Haberman

O **Haberman's Survival Dataset** Ã© um conjunto de dados clÃ¡ssico em Machine Learning, coletado no Hospital Billings de Chicago entre 1958 e 1970. ContÃ©m informaÃ§Ãµes sobre pacientes que passaram por cirurgia de cÃ¢ncer de mama.

### CaracterÃ­sticas do Dataset:
- **306 instÃ¢ncias** de pacientes
- **4 atributos** (3 features + 1 target)
- **Sem valores faltantes**
- **Balanceamento**: ~75% sobreviveram (classe 1), ~25% nÃ£o sobreviveram (classe 2)

### Atributos:
| Atributo | Tipo | DescriÃ§Ã£o | Faixa |
|----------|------|-----------|-------|
| `age` | int | Idade do paciente no momento da operaÃ§Ã£o | 30-83 anos |
| `year` | int | Ano da operaÃ§Ã£o | 1958-1969 |
| `nodes` | int | NÃºmero de nÃ³dulos linfÃ¡ticos axilares positivos detectados | 0-52 |
| `survival_status` | int | **Target**: Status de sobrevivÃªncia (1=sobreviveu â‰¥5 anos, 2=morreu <5 anos) | 1 ou 2 |

### ImportÃ¢ncia ClÃ­nica:
- **NÃ³dulos linfÃ¡ticos** sÃ£o o fator mais importante para prognÃ³stico
- **Idade** pode influenciar na capacidade de recuperaÃ§Ã£o
- **Ano da operaÃ§Ã£o** reflete avanÃ§os mÃ©dicos ao longo do tempo

## ğŸš€ Funcionalidades

- **AnÃ¡lise ExploratÃ³ria**: EstatÃ­sticas descritivas e distribuiÃ§Ã£o das classes
- **ComparaÃ§Ã£o de Algoritmos**: Testa 8 algoritmos diferentes com validaÃ§Ã£o cruzada
- **SeleÃ§Ã£o AutomÃ¡tica**: Escolhe o melhor modelo baseado na acurÃ¡cia
- **ValidaÃ§Ã£o Robusta**: Usa validaÃ§Ã£o cruzada 5-fold para avaliaÃ§Ã£o confiÃ¡vel
- **GeraÃ§Ã£o de Dados**: Cria dataset fictÃ­cio para demonstraÃ§Ã£o
- **VisualizaÃ§Ãµes**: GrÃ¡ficos de performance e distribuiÃ§Ãµes
- **PersistÃªncia**: Salva o melhor modelo treinado
- **API Backend**: ImplementaÃ§Ã£o com Flask em `api_ML.py`

## ğŸ¤– Algoritmos Implementados

O sistema compara os seguintes algoritmos:

1. **Logistic Regression** - ClassificaÃ§Ã£o linear probabilÃ­stica
2. **Random Forest** - Ensemble de Ã¡rvores de decisÃ£o
3. **Support Vector Machine (SVM)** - ClassificaÃ§Ã£o com margens mÃ¡ximas
4. **K-Nearest Neighbors (KNN)** - ClassificaÃ§Ã£o baseada em proximidade
5. **Decision Tree** - Ãrvore de decisÃ£o simples
6. **Naive Bayes** - ClassificaÃ§Ã£o probabilÃ­stica bayesiana
7. **Gradient Boosting** - Ensemble com boosting
8. **AdaBoost** - Adaptive boosting

## ğŸ› ï¸ Tecnologias Utilizadas

- **Python 3.x**
- **pandas 2.0.3**: ManipulaÃ§Ã£o e anÃ¡lise de dados
- **scikit-learn 1.3.0**: Algoritmos de Machine Learning
- **joblib 1.3.2**: SerializaÃ§Ã£o eficiente do modelo
- **matplotlib**: VisualizaÃ§Ãµes e grÃ¡ficos
- **numpy**: ComputaÃ§Ã£o numÃ©rica
- **Flask 2.3.3**: Framework web (para API)

## ğŸ“¦ InstalaÃ§Ã£o

1. Certifique-se de ter o Python instalado (versÃ£o 3.8 ou superior recomendada).
2. Clone o repositÃ³rio:
   ```bash
   git clone https://github.com/Gilmarregis/Projeto-Machine-Learning.git
   cd "Projeto-Machine-Learning"
   ```
3. Instale as dependÃªncias do projeto:
   ```bash
   pip install -r requirements.txt
   ```

## ğŸ”§ Como Usar

### Executar o Treinamento Completo

```bash
python ML_model.py
```

Este comando irÃ¡:
1. **Carregar** o dataset Haberman (306 amostras)
2. **Analisar** os dados (estatÃ­sticas, distribuiÃ§Ãµes)
3. **Comparar** 8 algoritmos com validaÃ§Ã£o cruzada 5-fold
4. **Selecionar** o melhor modelo automaticamente
5. **Treinar** o modelo final nos dados completos
6. **Validar** com mÃ©tricas detalhadas
7. **Salvar** o melhor modelo como `melhor_modelo_haberman.pkl`
8. **Gerar** dataset fictÃ­cio para demonstraÃ§Ã£o
9. **Aplicar** prediÃ§Ãµes nos dados fictÃ­cios
10. **Criar** visualizaÃ§Ãµes de performance

### Arquivos Gerados

ApÃ³s a execuÃ§Ã£o, os seguintes arquivos serÃ£o criados:
- `melhor_modelo_haberman.pkl` - Melhor modelo treinado
- `dados_ficticios_haberman.csv` - Dataset fictÃ­cio para teste
- `predicoes_haberman.csv` - PrediÃ§Ãµes nos dados fictÃ­cios
- GrÃ¡ficos de visualizaÃ§Ã£o (exibidos na tela)

### Executar a API

```bash
python api_ML.py
```

A API estarÃ¡ disponÃ­vel em http://localhost:5000/predict. Envie uma requisiÃ§Ã£o POST com dados como:

```json
{
    "age": 45,
    "year": 1965,
    "nodes": 3
}
```

#### Exemplo de Resposta:

```json
{
    "survival_status": 1,
    "probabilidade_sobrevivencia": 0.78,
    "probabilidade_obito": 0.22,
    "algoritmo_usado": "Random Forest",
    "confianca": "Alta"
}
```

## ğŸ“ˆ Performance Esperada

Baseado no dataset Haberman, os algoritmos tÃ­picamente alcanÃ§am:

- **AcurÃ¡cia**: 70-85% (dependendo do algoritmo)
- **Melhor algoritmo**: Geralmente Random Forest ou SVM
- **Baseline**: ~73% (predizer sempre a classe majoritÃ¡ria)
- **ValidaÃ§Ã£o cruzada**: Reduz overfitting e fornece estimativa confiÃ¡vel

### MÃ©tricas Avaliadas:
- **AcurÃ¡cia**: Percentual de prediÃ§Ãµes corretas
- **PrecisÃ£o**: Verdadeiros positivos / (VP + Falsos positivos)
- **Recall**: Verdadeiros positivos / (VP + Falsos negativos)
- **F1-Score**: MÃ©dia harmÃ´nica entre precisÃ£o e recall

## ğŸ”„ Fluxo do Projeto

```mermaid
graph TD
    A[Carregar Dataset Haberman] --> B[AnÃ¡lise ExploratÃ³ria]
    B --> C[PreparaÃ§Ã£o dos Dados]
    C --> D[DivisÃ£o Treino/ValidaÃ§Ã£o]
    D --> E[Comparar 8 Algoritmos]
    E --> F[ValidaÃ§Ã£o Cruzada 5-fold]
    F --> G[Selecionar Melhor Modelo]
    G --> H[Treinar Modelo Final]
    H --> I[ValidaÃ§Ã£o Final]
    I --> J[Salvar Modelo]
    J --> K[Gerar Dados FictÃ­cios]
    K --> L[Aplicar PrediÃ§Ãµes]
    L --> M[VisualizaÃ§Ãµes]
```

## ğŸ“ Estrutura do Projeto

```
Machine Learning/
â”œâ”€â”€ Machine Learning Backend.py    # CÃ³digo principal
â”œâ”€â”€ README.md                     # Este arquivo
â””â”€â”€ logistic_regression_model.pkl # Modelo treinado (gerado apÃ³s execuÃ§Ã£o)
```

## ğŸ¤ ContribuiÃ§Ã£o

1. Fork o projeto
2. Crie uma branch para sua feature (`git checkout -b feature/AmazingFeature`)
3. Commit suas mudanÃ§as (`git commit -m 'Add some AmazingFeature'`)
4. Push para a branch (`git push origin feature/AmazingFeature`)
5. Abra um Pull Request

## ğŸ“ LicenÃ§a

Este projeto estÃ¡ sob a licenÃ§a MIT. Veja o arquivo `LICENSE` para mais detalhes.

## ğŸ“ Contato

Para dÃºvidas ou sugestÃµes, entre em contato atravÃ©s dos issues do GitHub.

---

â­ Se este projeto foi Ãºtil para vocÃª, considere dar uma estrela!
