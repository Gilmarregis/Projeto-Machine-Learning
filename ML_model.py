# Implementar um algoritmo Machine learning para rodar no backend.
import pandas as pd
from pandas.plotting import scatter_matrix
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split, KFold, cross_val_score
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
from sklearn.naive_bayes import GaussianNB
from sklearn.svm import SVC
from sklearn.ensemble import RandomForestClassifier
from sklearn.neural_network import MLPClassifier
import joblib
import numpy as np
import warnings
warnings.filterwarnings('ignore')

print("=== AN√ÅLISE DE SOBREVIV√äNCIA - DATASET HABERMAN ===")
print("Atributos:")
print("1. Age: Idade do paciente na opera√ß√£o")
print("2. Year operation: Ano da opera√ß√£o (ano - 1900)")
print("3. Axillary nodes detected: N√∫mero de n√≥dulos axilares detectados")
print("4. Survival status: Status de sobreviv√™ncia")
print("   1 = paciente sobreviveu 5 anos ou mais")
print("   2 = paciente morreu em menos de 5 anos")
print("\n" + "="*60 + "\n")

# Carregar dataset
url = "dados/haberman.csv"
names = ['Age', 'Year_operation', 'Axillary_nodes_detected', 'Survival_status']
dataset = pd.read_csv(url, names=names)

print(f"Dataset carregado com {len(dataset)} registros")
print("\nPrimeiras 5 linhas:")
print(dataset.head())

print("\nEstat√≠sticas descritivas:")
print(dataset.describe())

print("\nDistribui√ß√£o das classes:")
print(dataset['Survival_status'].value_counts())

# Preparar dados
array = dataset.values
X = array[:, :3]  # Features: Age, Year_operation, Axillary_nodes_detected
Y = array[:, 3]   # Target: Survival_status

# Divis√£o treino/valida√ß√£o
validation_size = 0.30
seed = 10
X_train, X_validation, Y_train, Y_validation = train_test_split(
    X, Y, test_size=validation_size, random_state=seed
)

print(f"\nDados de treino: {len(X_train)} amostras")
print(f"Dados de valida√ß√£o: {len(X_validation)} amostras")

# Configura√ß√µes para valida√ß√£o cruzada
num_folds = 10
seed = 10
scoring = 'accuracy'

print("\n" + "="*60)
print("COMPARA√á√ÉO DE ALGORITMOS DE MACHINE LEARNING")
print("="*60)

# Lista de algoritmos para testar
algorithms = []
algorithms.append(('LR', LogisticRegression(random_state=seed, max_iter=1000)))
algorithms.append(('LDA', LinearDiscriminantAnalysis()))
algorithms.append(('KNN', KNeighborsClassifier()))
algorithms.append(('CART', DecisionTreeClassifier(random_state=seed)))
algorithms.append(('NB', GaussianNB()))
algorithms.append(('SVM', SVC(random_state=seed)))
algorithms.append(('NN', MLPClassifier(random_state=seed, max_iter=1000)))
algorithms.append(('RFC', RandomForestClassifier(random_state=seed)))

# Avaliar cada modelo
results = []
names = []
best_score = 0
best_model = None
best_name = ""

for name, algorithm in algorithms:
    kfold = KFold(n_splits=num_folds, random_state=seed, shuffle=True)
    cv_results = cross_val_score(algorithm, X_train, Y_train, cv=kfold, scoring=scoring)
    results.append(cv_results)
    names.append(name)
    
    mean_score = cv_results.mean()
    std_score = cv_results.std()
    
    print(f"{name:4}: {mean_score:.4f} (+/- {std_score:.4f})")
    
    # Identificar melhor modelo
    if mean_score > best_score:
        best_score = mean_score
        best_model = algorithm
        best_name = name

print(f"\nüèÜ MELHOR MODELO: {best_name} com acur√°cia de {best_score:.4f}")

# Treinar o melhor modelo com todos os dados de treino
print(f"\nTreinando {best_name} com dados completos...")
best_model.fit(X_train, Y_train)

# Fazer predi√ß√µes no conjunto de valida√ß√£o
predictions = best_model.predict(X_validation)
accuracy = accuracy_score(Y_validation, predictions)

print(f"\nüìä RESULTADOS NO CONJUNTO DE VALIDA√á√ÉO:")
print(f"Acur√°cia: {accuracy:.4f} ({accuracy*100:.2f}%)")
print("\nMatriz de Confus√£o:")
print(confusion_matrix(Y_validation, predictions))
print("\nRelat√≥rio de Classifica√ß√£o:")
print(classification_report(Y_validation, predictions))

# Salvar o melhor modelo
model_filename = f'best_model_{best_name.lower()}.pkl'
joblib.dump(best_model, model_filename)
print(f"\nüíæ Modelo salvo como '{model_filename}'")

# Tamb√©m salvar informa√ß√µes do modelo
model_info = {
    'model_name': best_name,
    'accuracy': accuracy,
    'cv_score': best_score,
    'features': names,
    'classes': [1, 2],
    'class_names': ['Sobreviveu >= 5 anos', 'Morreu < 5 anos']
}

import json
with open('model_info.json', 'w') as f:
    json.dump(model_info, f, indent=2)

print("üìã Informa√ß√µes do modelo salvas em 'model_info.json'")

print("\n" + "="*60)
print("TESTE COM DADOS FICT√çCIOS")
print("="*60)

# Criar dados fict√≠cios para teste
np.random.seed(42)
n_samples = 15

# Gerar dados realistas baseados nas estat√≠sticas do dataset original
fictitious_data = {
    'Age': np.random.randint(30, 70, n_samples),
    'Year_operation': np.random.randint(58, 70, n_samples),
    'Axillary_nodes_detected': np.random.randint(0, 30, n_samples)
}

df_fictitious = pd.DataFrame(fictitious_data)
print("\nDados fict√≠cios gerados:")
print(df_fictitious)

# Salvar dados fict√≠cios em CSV
df_fictitious.to_csv('dados_ficticios.csv', index=False)
print("\nüíæ Dados fict√≠cios salvos em 'dados_ficticios.csv'")

# Aplicar modelo nos dados fict√≠cios
fictitious_predictions = best_model.predict(df_fictitious.values)
fictitious_probabilities = best_model.predict_proba(df_fictitious.values)

print("\nüîÆ PREDI√á√ïES PARA DADOS FICT√çCIOS:")
for i, (pred, prob) in enumerate(zip(fictitious_predictions, fictitious_probabilities)):
    status = "Sobreviveu >= 5 anos" if pred == 1 else "Morreu < 5 anos"
    confidence = max(prob) * 100
    print(f"Paciente {i+1:2d}: {status} (Confian√ßa: {confidence:.1f}%)")

# Criar DataFrame com resultados
results_df = df_fictitious.copy()
results_df['Prediction'] = fictitious_predictions
results_df['Survival_Status'] = ['Sobreviveu >= 5 anos' if p == 1 else 'Morreu < 5 anos' 
                                for p in fictitious_predictions]
results_df['Confidence'] = [max(prob) * 100 for prob in fictitious_probabilities]

# Salvar resultados
results_df.to_csv('resultados_predicoes.csv', index=False)
print("\nüíæ Resultados salvos em 'resultados_predicoes.csv'")

# Estat√≠sticas das predi√ß√µes
survival_count = sum(fictitious_predictions == 1)
death_count = sum(fictitious_predictions == 2)

print(f"\nüìà RESUMO DAS PREDI√á√ïES:")
print(f"Pacientes que sobreviver√£o >= 5 anos: {survival_count} ({survival_count/n_samples*100:.1f}%)")
print(f"Pacientes que morrer√£o < 5 anos: {death_count} ({death_count/n_samples*100:.1f}%)")

# Visualiza√ß√£o simples
plt.figure(figsize=(12, 8))

# Subplot 1: Distribui√ß√£o das predi√ß√µes
plt.subplot(2, 2, 1)
plt.bar(['Sobreviveu >= 5 anos', 'Morreu < 5 anos'], [survival_count, death_count])
plt.title('Distribui√ß√£o das Predi√ß√µes')
plt.ylabel('N√∫mero de Pacientes')

# Subplot 2: Idade vs Predi√ß√£o
plt.subplot(2, 2, 2)
colors = ['green' if p == 1 else 'red' for p in fictitious_predictions]
plt.scatter(df_fictitious['Age'], fictitious_predictions, c=colors, alpha=0.7)
plt.xlabel('Idade')
plt.ylabel('Predi√ß√£o (1=Sobreviveu, 2=Morreu)')
plt.title('Idade vs Predi√ß√£o de Sobreviv√™ncia')

# Subplot 3: N√≥dulos vs Predi√ß√£o
plt.subplot(2, 2, 3)
plt.scatter(df_fictitious['Axillary_nodes_detected'], fictitious_predictions, c=colors, alpha=0.7)
plt.xlabel('N√≥dulos Axilares Detectados')
plt.ylabel('Predi√ß√£o (1=Sobreviveu, 2=Morreu)')
plt.title('N√≥dulos vs Predi√ß√£o de Sobreviv√™ncia')

# Subplot 4: Confian√ßa das predi√ß√µes
plt.subplot(2, 2, 4)
confidences = [max(prob) * 100 for prob in fictitious_probabilities]
plt.hist(confidences, bins=5, alpha=0.7, color='blue')
plt.xlabel('Confian√ßa da Predi√ß√£o (%)')
plt.ylabel('Frequ√™ncia')
plt.title('Distribui√ß√£o da Confian√ßa das Predi√ß√µes')

plt.tight_layout()
plt.savefig('analise_predicoes.png', dpi=300, bbox_inches='tight')
print("\nüìä Gr√°ficos salvos em 'analise_predicoes.png'")

print("\n" + "="*60)
print("‚úÖ AN√ÅLISE COMPLETA FINALIZADA!")
print("="*60)
print("\nArquivos gerados:")
print(f"‚Ä¢ {model_filename} - Modelo treinado")
print("‚Ä¢ model_info.json - Informa√ß√µes do modelo")
print("‚Ä¢ dados_ficticios.csv - Dataset fict√≠cio")
print("‚Ä¢ resultados_predicoes.csv - Predi√ß√µes com confian√ßa")
print("‚Ä¢ analise_predicoes.png - Visualiza√ß√µes")
print("\nüéØ O modelo est√° pronto para uso em produ√ß√£o!")

